{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 7)\n"
     ]
    }
   ],
   "source": [
    "%store -r df_classes\n",
    "\n",
    "\n",
    "print(df_classes[0].shape)\n",
    "# print(train.shape)\n",
    "# df_classes[0]\n",
    "# df_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train HMM\n",
    "\n",
    "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.3759&rep=rep1&type=pdf\n",
    "\n",
    "https://learning.oreilly.com/library/view/python-machine-learning/9781786464477/ch07s08.html#ch07lvl2sec94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Gaussian Mixture of model to find observation probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import pickle\n",
    "from hmmlearn import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# X0 = df_classes[0][['angles', 'x', 'y']]\n",
    "\n",
    "# GMM = GaussianMixture(n_components=3, random_state=0).fit(X0) BUGGATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from baum_welch import baum_welch\n",
    "\n",
    "# data = df_classes[0][['angles']].values\n",
    "# data_list_append = data.tolist()\n",
    "# data_list_append = [ three for one in data_list_append for two in one for three in two] \n",
    "\n",
    "# # TRY ONLY WI CURVATURE (ANGLE)\n",
    "# # 6 states\n",
    "# initial_prob = np.array([1, 0, 0, 0, 0, 0])\n",
    "# transition_prob = np.ones((6, 6))\n",
    "# transition_prob = transition_prob / np.sum(transition_prob, axis=1)\n",
    "# emission_prob = np.ones((6, 1)) # I don't know how many\n",
    "# emission_prob = emission_prob / np.sum(emission_prob, axis=1).reshape(-1, 1)\n",
    "\n",
    "# n_iter = 20\n",
    "# # To go, data has to be a list of numbers\n",
    "\n",
    "# transition_true, emission_true = baum_welch(data_list_append, initial_prob, transition_prob, emission_prob, n_iter)\n",
    "\n",
    "# print(\"new transition_prob: \", transition_true, \"\\nnew emission_prob: \", emission_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hmmlearn.readthedocs.io/en/latest/tutorial.html#working-with-multiple-sequences\n",
    "\n",
    "#           Delete this cell\n",
    "\n",
    "# data_true = train[['angles']].values.tolist()\n",
    "# data_list_try = np.array([ [three] for one in data_true for two in one for three in two])\n",
    "# len_list_try = [len(two) for one in data_true for two in one ]\n",
    "\n",
    "\n",
    "# # print(data_list_try)\n",
    "# # print(data_list_try.shape)\n",
    "# # print(type(len_list_try))\n",
    "\n",
    "# hmm.GaussianHMM(n_components=6).fit(data_list_try, len_list_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling probabilities of class  0  of  9  classes\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Must be overridden in subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/thomas/Scrivania/PRIMO ANNO 2/Probabilistic ML/Project/scripts/hmm.ipynb Cella 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mtransmat_ \u001b[39m=\u001b[39m transition_prob\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39memissionprob_ \u001b[39m=\u001b[39m emission_prob\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(data_list, len_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=25'>26</a>\u001b[0m \u001b[39m# print(\"initial probability: \", model.startprob_)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=26'>27</a>\u001b[0m \u001b[39m# print(f'transition: \\n{model.transmat_}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=27'>28</a>\u001b[0m \u001b[39m# print(f'emission: \\n{model.emissionprob_}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thomas/Scrivania/PRIMO%20ANNO%202/Probabilistic%20ML/Project/scripts/hmm.ipynb#ch0000007?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(n_class)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhmm_model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f: \u001b[39m#Save model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.9/site-packages/hmmlearn/base.py:508\u001b[0m, in \u001b[0;36mBaseHMM.fit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    505\u001b[0m curr_log_prob \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    506\u001b[0m \u001b[39mfor\u001b[39;00m sub_X \u001b[39min\u001b[39;00m _utils\u001b[39m.\u001b[39msplit_X_lengths(X, lengths):\n\u001b[1;32m    507\u001b[0m     lattice, log_prob, posteriors, fwdlattice, bwdlattice \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 508\u001b[0m             impl(sub_X)\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Derived HMM classes will implement the following method to\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# update their probability distributions, so keep\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39m# a single call to this method for simplicity.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accumulate_sufficient_statistics(\n\u001b[1;32m    513\u001b[0m         stats, sub_X, lattice, posteriors, fwdlattice,\n\u001b[1;32m    514\u001b[0m         bwdlattice)\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.9/site-packages/hmmlearn/base.py:540\u001b[0m, in \u001b[0;36mBaseHMM._fit_log\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_log\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 540\u001b[0m     log_frameprob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_log_likelihood(X)\n\u001b[1;32m    541\u001b[0m     log_prob, fwdlattice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_forward_log_pass(log_frameprob)\n\u001b[1;32m    542\u001b[0m     bwdlattice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_backward_log_pass(log_frameprob)\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.9/site-packages/hmmlearn/base.py:710\u001b[0m, in \u001b[0;36mBaseHMM._compute_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_likelihood(X))\n\u001b[1;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust be overridden in subclass\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Must be overridden in subclass"
     ]
    }
   ],
   "source": [
    "n_iter=1000\n",
    "feature_involved = ['angles_tangent']\n",
    "\n",
    "\n",
    "for n_class, _ in df_classes.items():\n",
    "    print(\"Modelling probabilities of class \", n_class,\" of \", len(df_classes), \" classes\")\n",
    "    # model = hmm.GaussianHMM(n_components=6, n_iter=n_iter, verbose=False, algorithm=\"viterbi\")\n",
    "    model = base.BaseHMM(n_components=6, n_iter=n_iter)\n",
    "    data_true = df_classes[n_class][feature_involved].values.tolist()\n",
    "    data_list = np.array([ [three] for one in data_true for two in one for three in two])\n",
    "    len_list = [len(two) for one in data_true for two in one ]\n",
    "\n",
    "    initial_prob = np.array([1, 0, 0, 0, 0, 0])\n",
    "    transition_prob = np.ones((6, 6))\n",
    "    transition_prob = transition_prob / np.sum(transition_prob, axis=1)\n",
    "    emission_prob = np.ones((6, 1)) # I don't know how many\n",
    "    emission_prob = emission_prob / np.sum(emission_prob, axis=1)\n",
    "\n",
    "    model.startprob_ = initial_prob\n",
    "    model.transmat_ = transition_prob\n",
    "    model.emissionprob_ = emission_prob\n",
    "\n",
    "\n",
    "    model.fit(data_list, len_list)\n",
    "\n",
    "    # print(\"initial probability: \", model.startprob_)\n",
    "    # print(f'transition: \\n{model.transmat_}')\n",
    "    # print(f'emission: \\n{model.emissionprob_}')\n",
    "\n",
    "    with open ('models/'+str(n_class)+'hmm_model.pkl', 'wb') as f: #Save model\n",
    "        pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f162362b51a040b66da23130964be17c9a4290e709b2d7f75b268249f5b26fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
